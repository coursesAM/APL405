# APL405: Machine Learning for Mechanics (Winter semester 2023)


## Course Info

**Credit:** 3 units (2-0-2) <br> <br>

**Instructors:** [Prof. Rajdip Nayek](https://sites.google.com/view/rajdip-nayek/) (rajdipn@am.iitd.ac.in) <br> <br>

**TA 1:** Tapas Tripura (amz198096@am.iitd.ac.in) <br> 
**TA 2:** Shailesh Garg (amz208472@am.iitd.ac.in) <br>
**TA 3:** Tushar (amz218561@am.iitd.ac.in) <br>
**TA 4:** Sahil Kashyap (amz218561@am.iitd.ac.in) <br><br>

**Class timings:** Mon, Thu & Fri (11:00 to 11:50 AM) at LHC350 <br><br>

**Practical Session:** Fri (3:15 to 5:00 PM) at LHC 606 <br> <br>

**Office hours (TA)**: By email appointment <br> 
**Office hours (Instructor)**: **Prof. Rajdip Nayek** (Thu 5-6pm) **Office** Block V-418D <br><br>

**Intended audience:** BTech students in Applied Mechanics, Materials, and Mechanical Engineering disciplines.

**NOTE**-For *all course related emails*, please put **APL405** in the subject line <br>

## Course Content
This is an introductory course to statistical machine learning for students with some background in calculus, linear algebra and statistics. The course is focusing on supervised learning, i.e, classification and regression. The course will cover a range of methods used in machine learning and data science, including:
- Linear regression
- Classification via logistic regression and k nearest neighbour
- Linear and quadratic discriminant analysis
- Regression and classification trees
- Bagging and boosting
- Neural networks and deep learning

These methods will be studied from various applications throughout the course. The course also covers important practical considerations such as cross-validation, model selection and the bias-variance trade-off. The course includes theory (e.g., derivations and proofs) as well as practice (notably the lab and the course project). The practical part will be implemented using Python.

## Course Structure
* Introduction 
* Supervised Learning 
* k-NN 
* Decision Trees 
* Linear Regression and Logistic regression 
* Polynomial regression
* SVR and SVM
* Bias-Variance decomposition
* Building blocks of a ML algorithm
  * Principles of Parametric modelling
  * Loss function vs likelihood based models
  * Regularization
  * Parameter optimization
  * Hyperparameter optimization
  * Practical aspects
    * One-hot encoding
    * Binning
    * Input normalization
    * Three sets: Train, test, validation
    * Model performance assessment: 
      * Confusion matrix
      * Precision
      * Accuracy
* Bayesian Approach and Gaussian Process (3-4 lectures)
* Neural Networks (4 lectures) [100 page ML book]
  * FNN
  * Training a neural network using back propagation
  * CNN 
* Ensemble algorithms
  * Bagging
  * Boosting
  * Random Forest
* Representation Learning and Dimensionality reduction
  * Autoencoders
  * PCA

## Lecture Schedule

|Module#| Main Topic | Sub Topics|Lecture Notes| 
|:----------:|:----------------------------: |:------------------:|:-------------:|
|Module 00| Introduction | | [Lecture 1]  |
|Module 01| A Preliminary Approach <br> to Supervised Learning| Background <br> k-Nearest Neighbours <br> Decision Trees | [Lecture 2] <br> [Lecture 3] <br> [Lecture 4]| 
|Module 02| Basic Parametric Models | Linear regression <br> Logistic Regression <br> Regularization | [Lecture 5] <br> [Lecture 6] <br> [Lecture 7]| 
|Module 03| Evaluating Performance | Bias-variance decomposition | [Lecture 8] |
|Module 04| Learning Parametric Models | Loss functions and likelihood-based models <br> Parameter Optimization | [Lecture 9] <br> [Lecture 10] 






## Practical Schedule

|Week# | Topics| Practical Questions| 
|:------:|:---------:|:--------:|
| Week 1 | Probability refresher | [Practical 1](Practical/Practical_1.pdf) | 
| Week 2 | k-Nearest Neighbours  | [Practical 2](Practical/Practical_2.pdf) | 




## Table of Contents
- [Course Outline](#course-outline)
- [Course Layout](#course-layout)
- [Course References](#course-references)
- [Grading](#grading)
- [Course Attendance](#course-attendance)
- [Quiz](#quiz)
- [Policy for Cheating](#policy-for-cheating)

## Course Outline
This is the first course where deformation of solid bodies and the underlying concepts are introduced to undergraduate students. The course begins by building foundation of the concepts of stress and strain in three-dimensional deformable bodies. It further uses these concepts to study extension, torsion and bending of beams. The one-dimensional theory of beams are also introduced. Various theories of failure that are critical for design of machine elements in industry will also be discussed.

## Course Layout
- Mathematical preliminaries and notation; Concept of Traction vector; Concept of Stress tensor
- Stress tensor and its representation in Cartesian coordinate system; Transformation of stress matrix; Equations of equilibrium; Symmetry of stress tensor
- State of stress in simple cases; Principal stress components and principal planes; Maximizing shear component of traction; Mohrâ€™s circle

## Course References
This course is not based on any particular textbook. However, the course materials have been prepared using the following four references:
* Mathematics for Machine Learning [[free pdf](https://mml-book.github.io/book/mml-book.pdf)]
* Christopher Bishop, *"Pattern Recognition and Machine Learning"*, Springer, 2006.
* Andriy Burkov, *"The Hundred Page Machine Learning Book"*, 2019 [[free pdf](http://ema.cri-info.cm/wp-content/uploads/2019/07/2019BurkovTheHundred-pageMachineLearning.pdf)].
*  Andreas Lindholm et. al., *"Machine Learning: A First Course for Engineers and Scientists"*, Cambridge University Press, 2022 [[free pdf](http://smlbook.org/book/sml-book-draft-latest.pdf)]


## Grading  

|Component|Scores| 
|:---|:-----:|
|**Attendance** | 10 | 
|**Assignments**| 15 |
|**Project**    | 30 |
|**Minor #1**  (10L) | 10 | 
|**Minor #2**   | 10 | 
|**Major**      | 25 | 
|**Total**      | 100| 

## Course Attendance
Students are highly encouraged to attend all classes. They have to attend the classes and practicals to receive 10 point attendance scores. Class attendance will be taken **via Timble**. Attendance in practicals will be taken by TAs. Please mark yourself **IN and OUT** for each class. In case of unavoidable absence, such as illness, please send an appropriate email **within a week before/after absence** with email subject specifying the subject code APL 405. <br>

**A minimum of 75% attendance is required for passing the course.**
